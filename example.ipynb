{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87607bfc",
   "metadata": {},
   "source": [
    "# MLflow Example\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Example is enhanced version of original in [MLflow mlflow.sklearn documentation](https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html). It demonstrates how to use MLflow to log and visualize the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767eb2a0ee724eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:28:23.767814Z",
     "start_time": "2024-05-29T13:28:21.268711Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e086d7",
   "metadata": {},
   "source": [
    "## Tensorflow Example\n",
    "\n",
    "https://mlflow.org/docs/latest/deep-learning/tensorflow/guide/index.html\n",
    "\n",
    "\n",
    "## Pytorch Example\n",
    "\n",
    "https://mlflow.org/docs/latest/deep-learning/pytorch/guide/index.html\n",
    "\n",
    "\n",
    "## Sklearn Linear Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb62438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/12 14:49:36 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51857f1",
   "metadata": {},
   "source": [
    "### Load dataset and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822fda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"multi_class\": \"auto\",\n",
    "    \"random_state\": 8888,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a2e6e",
   "metadata": {},
   "source": [
    "### Prepare model and mlflow tracking\n",
    "\n",
    "Log everything manually... because you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d616f4a9c989261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:28:31.848053Z",
     "start_time": "2024-05-29T13:28:23.771467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://192.168.30.21:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=\"Basic LR Model\"):\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    for i in range(10):\n",
    "        # Train the model\n",
    "        lr = LogisticRegression(**params)\n",
    "        lr.fit(X_train, y_train)\n",
    "        # compute metrics for trained model\n",
    "        y_train_pred = lr.predict(X_train)\n",
    "        accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "        precision_train = precision_score(y_train, y_train_pred, average=\"macro\")\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = lr.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "        # Log the loss metric\n",
    "        mlflow.log_metrics({\"accuracy\": accuracy,\n",
    "                            \"precision\": precision,\n",
    "                            \"accuracy_train\": accuracy_train,\n",
    "                            \"precision_train\": precision_train                            \n",
    "                            }, step=i)\n",
    "        \n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lr.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        artifact_path=\"iris_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"tracking-quickstart\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ef5195",
   "metadata": {},
   "source": [
    "## Use autologging\n",
    "\n",
    "If you are unsure what to log, you can easily use autolog.\n",
    "This will cover most of the basic standard metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31316b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autolog to log all parameters and metrics implicitly\n",
    "mlflow.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic LR Model\"):\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    lr = LogisticRegression(**params)\n",
    "    lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdea6d5",
   "metadata": {},
   "source": [
    "### Predict and evaluate - log table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bdfda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(X_test, columns=datasets.load_iris().feature_names)\n",
    "results[\"actual_class\"] = y_test\n",
    "results[\"predicted_class\"] = lr.predict(X_test)\n",
    "mlflow.log_table(data=results, artifact_file=\"evaluation/test_set.json\", run_id=\"ff589d2a872d4ffcbe1a7bed0547649a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc7c93",
   "metadata": {},
   "source": [
    "### Load model from mlflow and infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37b4033c584fc11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:28:32.379216Z",
     "start_time": "2024-05-29T13:28:31.849181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12af4a6ad704415a89523a43cdf615be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                6.1               2.8                4.7               1.2   \n",
       "1                5.7               3.8                1.7               0.3   \n",
       "2                7.7               2.6                6.9               2.3   \n",
       "3                6.0               2.9                4.5               1.5   \n",
       "\n",
       "   actual_class  predicted_class  \n",
       "0             1                1  \n",
       "1             0                0  \n",
       "2             2                2  \n",
       "3             1                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either downlaod the model via uri from model_info or find the uri from the model registry or manually in the UI\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
